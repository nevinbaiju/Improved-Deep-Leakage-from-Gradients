{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6380e43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.io import read_image\n",
    "\n",
    "import pickle\n",
    "import PIL.Image as Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2566e0",
   "metadata": {},
   "source": [
    "## Model declarations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb491b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, channel=3, hideen=588, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        act = nn.Sigmoid\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channel, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=1),\n",
    "            act(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hideen, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ba3774",
   "metadata": {},
   "source": [
    "## Misc functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbc65734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    try:\n",
    "        if hasattr(m, \"weight\"):\n",
    "            m.weight.data.uniform_(-0.5, 0.5)\n",
    "    except Exception:\n",
    "        print('warning: failed in weights_init for %s.weight' % m._get_name())\n",
    "    try:\n",
    "        if hasattr(m, \"bias\"):\n",
    "            m.bias.data.uniform_(-0.5, 0.5)\n",
    "    except Exception:\n",
    "        print('warning: failed in weights_init for %s.bias' % m._get_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b8862b",
   "metadata": {},
   "source": [
    "## Data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c6c984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_from_Image(Dataset):\n",
    "    def __init__(self, imgs, labs, transform=None):\n",
    "        self.imgs = imgs # img paths\n",
    "        self.labs = labs # labs is ndarray\n",
    "        self.transform = transform\n",
    "        del imgs, labs\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labs.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lab = self.labs[idx]\n",
    "        img = Image.open(self.imgs[idx])\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "918a92e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lfw_dataset(lfw_path, shape_img):\n",
    "    images_all = []\n",
    "    labels_all = []\n",
    "    folders = os.listdir(lfw_path)\n",
    "    for foldidx, fold in enumerate(folders):\n",
    "        files = os.listdir(os.path.join(lfw_path, fold))\n",
    "        for f in files:\n",
    "            if len(f) > 4 and f[-4:] == '.jpg':\n",
    "                images_all.append(os.path.join(lfw_path, fold, f))\n",
    "                labels_all.append(foldidx)\n",
    "\n",
    "    transform = transforms.Compose([transforms.Resize(size=shape_img)])\n",
    "    dst = Dataset_from_Image(images_all, np.asarray(labels_all, dtype=int), transform=transform)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03fb1403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset, data_path):\n",
    "    data_params = {}\n",
    "    if dataset == 'MNIST':\n",
    "        data_params['shape_img'] = (28, 28)\n",
    "        data_params['num_classes'] = 10\n",
    "        data_params['channel'] = 1\n",
    "        data_params['hidden'] = 588\n",
    "        data_params['dst'] = datasets.MNIST(data_path, download=False)\n",
    "\n",
    "    elif dataset == 'cifar100':\n",
    "        data_params['shape_img'] = (32, 32)\n",
    "        data_params['num_classes'] = 100\n",
    "        data_params['channel'] = 3\n",
    "        data_params['hidden'] = 768\n",
    "        data_params['dst'] = datasets.CIFAR100(data_path, download=False)\n",
    "\n",
    "    elif dataset == 'lfw':\n",
    "        data_params['shape_img'] = (32, 32)\n",
    "        data_params['num_classes'] = 5749\n",
    "        data_params['channel'] = 3\n",
    "        data_params['hidden'] = 768\n",
    "        data_params['lfw_path'] = os.path.join(root_path, '../data/lfw')\n",
    "        data_params['dst'] = lfw_dataset(data_params['lfw_path'], data_params['shape_img'])\n",
    "\n",
    "    else:\n",
    "        exit('unknown dataset')\n",
    "        \n",
    "    return data_params\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb30d53",
   "metadata": {},
   "source": [
    "## Args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200b34fe",
   "metadata": {},
   "source": [
    "##### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d45ce0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'lfw'\n",
    "root_path = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79904d15",
   "metadata": {},
   "source": [
    "##### Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e7f1fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1.0\n",
    "num_dummy = 1\n",
    "Iteration = 300\n",
    "num_exp = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "efc10dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4cbbaf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = transforms.Compose([transforms.ToTensor()])\n",
    "tp = transforms.Compose([transforms.ToPILImage()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6fa043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '.'\n",
    "data_path = os.path.join(root_path, '../data').replace('\\\\', '/')\n",
    "save_path = os.path.join(root_path, 'results/iDLG_%s'%dataset).replace('\\\\', '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4db421f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('results'):\n",
    "    os.mkdir('results')\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715f76e5",
   "metadata": {},
   "source": [
    "#### Choosing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4109281c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = load_data(dataset, data_path)\n",
    "dst = data_params['dst']\n",
    "num_classes = data_params['num_classes']\n",
    "hidden = data_params['hidden']\n",
    "channels = data_params['channel']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab684a2",
   "metadata": {},
   "source": [
    "Lenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "848c4afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LeNet(channel=channels,  \n",
    "            hideen=hidden,\n",
    "            num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed8dff76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (body): Sequential(\n",
       "    (0): Conv2d(3, 12, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (1): Sigmoid()\n",
       "    (2): Conv2d(12, 12, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (3): Sigmoid()\n",
       "    (4): Conv2d(12, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=5749, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597ae439",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0984da38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 0|1000 experiment\n",
      "IDLG, Try to generate 1 images\n",
      "lr = 1.0\n",
      "[2022-11-07 14:47:07] 0 loss = 26.37602997, mse = 1.24402022\n",
      "[2022-11-07 14:47:22] 10 loss = 0.56964219, mse = 0.50012082\n",
      "[2022-11-07 14:47:36] 20 loss = 0.06527516, mse = 0.20507681\n",
      "[2022-11-07 14:47:49] 30 loss = 0.01614678, mse = 0.09667882\n",
      "[2022-11-07 14:48:02] 40 loss = 0.00501796, mse = 0.04621727\n",
      "[2022-11-07 14:48:14] 50 loss = 0.00190647, mse = 0.02259993\n",
      "[2022-11-07 14:48:27] 60 loss = 0.00074923, mse = 0.01034877\n",
      "[2022-11-07 14:48:40] 70 loss = 0.00029496, mse = 0.00516237\n",
      "[2022-11-07 14:48:54] 80 loss = 0.00013428, mse = 0.00266167\n",
      "[2022-11-07 14:49:08] 90 loss = 0.00006122, mse = 0.00134821\n",
      "[2022-11-07 14:49:22] 100 loss = 0.00003061, mse = 0.00067289\n",
      "[2022-11-07 14:49:36] 110 loss = 0.00001533, mse = 0.00032608\n",
      "[2022-11-07 14:49:49] 120 loss = 0.00000704, mse = 0.00014324\n",
      "[2022-11-07 14:50:02] 130 loss = 0.00000335, mse = 0.00006675\n",
      "[2022-11-07 14:50:16] 140 loss = 0.00000171, mse = 0.00003373\n",
      "[2022-11-07 14:50:31] 150 loss = 0.00000089, mse = 0.00001704\n",
      "imidx_list: [8986]\n",
      "gt_label: [3752] lab_iDLG: 3752\n",
      "----------------------\n",
      "\n",
      "\n",
      "running 1|1000 experiment\n",
      "IDLG, Try to generate 1 images\n",
      "lr = 1.0\n",
      "[2022-11-07 14:50:33] 0 loss = 36.91627884, mse = 1.07351398\n",
      "[2022-11-07 14:50:44] 10 loss = 0.86180550, mse = 0.31682691\n",
      "[2022-11-07 14:50:56] 20 loss = 0.05117119, mse = 0.06540421\n",
      "[2022-11-07 14:51:08] 30 loss = 0.00789426, mse = 0.02018391\n",
      "[2022-11-07 14:51:20] 40 loss = 0.00181838, mse = 0.00677167\n",
      "[2022-11-07 14:51:33] 50 loss = 0.00043779, mse = 0.00243535\n",
      "[2022-11-07 14:51:47] 60 loss = 0.00013791, mse = 0.00115271\n",
      "[2022-11-07 14:52:01] 70 loss = 0.00005898, mse = 0.00063580\n",
      "[2022-11-07 14:52:15] 80 loss = 0.00002737, mse = 0.00035440\n",
      "[2022-11-07 14:52:29] 90 loss = 0.00001426, mse = 0.00020177\n",
      "[2022-11-07 14:52:44] 100 loss = 0.00000716, mse = 0.00009676\n",
      "[2022-11-07 14:52:58] 110 loss = 0.00000342, mse = 0.00004414\n",
      "[2022-11-07 14:53:12] 120 loss = 0.00000173, mse = 0.00002206\n",
      "[2022-11-07 14:53:27] 130 loss = 0.00000099, mse = 0.00001210\n",
      "imidx_list: [6106]\n",
      "gt_label: [2768] lab_iDLG: 2768\n",
      "----------------------\n",
      "\n",
      "\n",
      "running 2|1000 experiment\n",
      "IDLG, Try to generate 1 images\n",
      "lr = 1.0\n",
      "[2022-11-07 14:53:29] 0 loss = 45.73926926, mse = 1.08288872\n",
      "[2022-11-07 14:53:41] 10 loss = 0.29658908, mse = 0.17285638\n",
      "[2022-11-07 14:53:54] 20 loss = 0.02203274, mse = 0.04521083\n",
      "[2022-11-07 14:54:06] 30 loss = 0.00353961, mse = 0.01352136\n",
      "[2022-11-07 14:54:19] 40 loss = 0.00083142, mse = 0.00409705\n",
      "[2022-11-07 14:54:31] 50 loss = 0.00022335, mse = 0.00139707\n",
      "[2022-11-07 14:54:44] 60 loss = 0.00006033, mse = 0.00043892\n",
      "[2022-11-07 14:54:57] 70 loss = 0.00002037, mse = 0.00016931\n",
      "[2022-11-07 14:55:10] 80 loss = 0.00000709, mse = 0.00005745\n",
      "[2022-11-07 14:55:23] 90 loss = 0.00000215, mse = 0.00001576\n",
      "[2022-11-07 14:55:37] 100 loss = 0.00000076, mse = 0.00000553\n",
      "imidx_list: [11281]\n",
      "gt_label: [4888] lab_iDLG: 4888\n",
      "----------------------\n",
      "\n",
      "\n",
      "running 3|1000 experiment\n",
      "IDLG, Try to generate 1 images\n",
      "lr = 1.0\n",
      "[2022-11-07 14:55:39] 0 loss = 25.44907570, mse = 1.10306537\n",
      "[2022-11-07 14:55:52] 10 loss = 0.37118614, mse = 0.27674305\n",
      "[2022-11-07 14:56:05] 20 loss = 0.03780653, mse = 0.09163753\n",
      "[2022-11-07 14:56:18] 30 loss = 0.00749047, mse = 0.03529815\n",
      "[2022-11-07 14:56:31] 40 loss = 0.00197181, mse = 0.01522936\n",
      "[2022-11-07 14:56:45] 50 loss = 0.00066032, mse = 0.00734649\n",
      "[2022-11-07 14:57:00] 60 loss = 0.00024600, mse = 0.00341161\n",
      "[2022-11-07 16:44:45] 70 loss = 0.00010119, mse = 0.00162329\n",
      "[2022-11-07 16:45:05] 80 loss = 0.00004141, mse = 0.00078336\n",
      "[2022-11-07 16:45:22] 90 loss = 0.00001901, mse = 0.00041827\n",
      "[2022-11-07 16:45:40] 100 loss = 0.00000918, mse = 0.00022298\n",
      "[2022-11-07 16:45:56] 110 loss = 0.00000479, mse = 0.00012607\n",
      "[2022-11-07 16:46:13] 120 loss = 0.00000255, mse = 0.00007161\n",
      "[2022-11-07 16:46:31] 130 loss = 0.00000140, mse = 0.00004184\n",
      "[2022-11-07 16:46:48] 140 loss = 0.00000091, mse = 0.00002742\n",
      "imidx_list: [12834]\n",
      "gt_label: [5541] lab_iDLG: 5541\n",
      "----------------------\n",
      "\n",
      "\n",
      "running 4|1000 experiment\n",
      "IDLG, Try to generate 1 images\n",
      "lr = 1.0\n",
      "[2022-11-07 16:46:51] 0 loss = 43.54289627, mse = 1.13358390\n",
      "[2022-11-07 16:47:06] 10 loss = 0.78734446, mse = 0.32936227\n",
      "[2022-11-07 16:47:22] 20 loss = 0.06797161, mse = 0.09032375\n",
      "[2022-11-07 16:47:38] 30 loss = 0.01009233, mse = 0.02565652\n",
      "[2022-11-07 16:47:53] 40 loss = 0.00200879, mse = 0.00914515\n",
      "[2022-11-07 16:48:10] 50 loss = 0.00059842, mse = 0.00380595\n",
      "[2022-11-07 16:48:27] 60 loss = 0.00020949, mse = 0.00152571\n",
      "[2022-11-07 16:48:44] 70 loss = 0.00007245, mse = 0.00060785\n",
      "[2022-11-07 16:49:02] 80 loss = 0.00002893, mse = 0.00029508\n",
      "[2022-11-07 16:49:20] 90 loss = 0.00001208, mse = 0.00014925\n",
      "[2022-11-07 16:49:37] 100 loss = 0.00000580, mse = 0.00008907\n",
      "[2022-11-07 16:49:55] 110 loss = 0.00000305, mse = 0.00005941\n",
      "[2022-11-07 16:50:12] 120 loss = 0.00000186, mse = 0.00004517\n",
      "[2022-11-07 16:50:28] 130 loss = 0.00000133, mse = 0.00003763\n",
      "[2022-11-07 16:50:40] 140 loss = 0.00000108, mse = 0.00003313\n",
      "[2022-11-07 16:50:49] 150 loss = 0.00000095, mse = 0.00003090\n",
      "imidx_list: [9113]\n",
      "gt_label: [3810] lab_iDLG: 3810\n",
      "----------------------\n",
      "\n",
      "\n",
      "running 5|1000 experiment\n",
      "IDLG, Try to generate 1 images\n",
      "lr = 1.0\n",
      "[2022-11-07 16:50:52] 0 loss = 36.73624802, mse = 1.22031474\n",
      "[2022-11-07 16:51:07] 10 loss = 0.84852046, mse = 0.51955909\n",
      "[2022-11-07 16:51:22] 20 loss = 0.13895607, mse = 0.24233836\n",
      "[2022-11-07 16:51:37] 30 loss = 0.03694183, mse = 0.12516505\n",
      "[2022-11-07 16:51:52] 40 loss = 0.01177990, mse = 0.06436348\n",
      "[2022-11-07 16:52:09] 50 loss = 0.00421777, mse = 0.03332778\n",
      "[2022-11-07 16:52:26] 60 loss = 0.00172616, mse = 0.01815899\n",
      "[2022-11-07 16:52:42] 70 loss = 0.00071384, mse = 0.00975702\n",
      "[2022-11-07 16:52:59] 80 loss = 0.00032463, mse = 0.00568543\n",
      "[2022-11-07 16:53:17] 90 loss = 0.00016814, mse = 0.00356718\n",
      "[2022-11-07 16:53:33] 100 loss = 0.00009847, mse = 0.00228580\n",
      "[2022-11-07 16:53:49] 110 loss = 0.00005572, mse = 0.00134095\n",
      "[2022-11-07 16:54:02] 120 loss = 0.00003535, mse = 0.00087464\n",
      "[2022-11-07 16:54:14] 130 loss = 0.00002169, mse = 0.00054465\n",
      "[2022-11-07 16:54:28] 140 loss = 0.00001259, mse = 0.00032166\n",
      "[2022-11-07 16:54:45] 150 loss = 0.00000790, mse = 0.00020028\n",
      "[2022-11-07 16:55:03] 160 loss = 0.00000495, mse = 0.00013072\n",
      "[2022-11-07 16:55:20] 170 loss = 0.00000327, mse = 0.00009330\n",
      "[2022-11-07 16:55:37] 180 loss = 0.00000237, mse = 0.00007177\n",
      "[2022-11-07 16:56:07] 190 loss = 0.00000179, mse = 0.00005530\n",
      "[2022-11-07 16:56:23] 200 loss = 0.00000148, mse = 0.00004847\n",
      "[2022-11-07 16:56:26] 210 loss = 0.00000145, mse = 0.00004769\n",
      "[2022-11-07 16:56:29] 220 loss = 0.00000145, mse = 0.00004769\n",
      "[2022-11-07 16:56:32] 230 loss = 0.00000145, mse = 0.00004769\n",
      "[2022-11-07 16:56:34] 240 loss = 0.00000145, mse = 0.00004769\n",
      "[2022-11-07 16:56:37] 250 loss = 0.00000145, mse = 0.00004769\n",
      "[2022-11-07 16:56:39] 260 loss = 0.00000145, mse = 0.00004769\n",
      "[2022-11-07 16:56:42] 270 loss = 0.00000145, mse = 0.00004769\n",
      "[2022-11-07 16:56:44] 280 loss = 0.00000145, mse = 0.00004769\n",
      "[2022-11-07 16:56:47] 290 loss = 0.00000145, mse = 0.00004769\n",
      "imidx_list: [12]\n",
      "gt_label: [9] lab_iDLG: 9\n",
      "----------------------\n",
      "\n",
      "\n",
      "running 6|1000 experiment\n",
      "IDLG, Try to generate 1 images\n",
      "lr = 1.0\n",
      "[2022-11-07 16:56:55] 0 loss = 62.56890488, mse = 1.30241323\n",
      "[2022-11-07 16:57:14] 10 loss = 1.74182653, mse = 0.54637438\n",
      "[2022-11-07 16:57:29] 20 loss = 0.21104594, mse = 0.20627816\n",
      "[2022-11-07 16:57:45] 30 loss = 0.03327063, mse = 0.07709908\n",
      "[2022-11-07 16:58:02] 40 loss = 0.00758164, mse = 0.03355922\n",
      "[2022-11-07 16:58:18] 50 loss = 0.00253919, mse = 0.01561779\n",
      "[2022-11-07 16:58:36] 60 loss = 0.00088720, mse = 0.00731895\n",
      "[2022-11-07 16:58:53] 70 loss = 0.00034557, mse = 0.00366442\n",
      "[2022-11-07 16:59:09] 80 loss = 0.00015420, mse = 0.00201764\n",
      "[2022-11-07 16:59:25] 90 loss = 0.00008292, mse = 0.00124303\n",
      "[2022-11-07 16:59:41] 100 loss = 0.00004615, mse = 0.00075870\n",
      "[2022-11-07 16:59:57] 110 loss = 0.00002579, mse = 0.00046710\n",
      "[2022-11-07 17:00:14] 120 loss = 0.00001674, mse = 0.00031247\n",
      "[2022-11-07 17:00:31] 130 loss = 0.00001096, mse = 0.00020980\n",
      "[2022-11-07 17:00:47] 140 loss = 0.00000761, mse = 0.00014941\n",
      "[2022-11-07 17:01:04] 150 loss = 0.00000530, mse = 0.00009827\n",
      "[2022-11-07 17:01:23] 160 loss = 0.00000356, mse = 0.00006674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-07 17:01:43] 170 loss = 0.00000246, mse = 0.00004539\n",
      "[2022-11-07 17:01:52] 180 loss = 0.00000214, mse = 0.00003970\n",
      "[2022-11-07 17:01:54] 190 loss = 0.00000214, mse = 0.00003970\n",
      "[2022-11-07 17:01:56] 200 loss = 0.00000214, mse = 0.00003970\n",
      "[2022-11-07 17:01:58] 210 loss = 0.00000214, mse = 0.00003970\n",
      "[2022-11-07 17:02:00] 220 loss = 0.00000214, mse = 0.00003970\n",
      "[2022-11-07 17:02:02] 230 loss = 0.00000214, mse = 0.00003970\n",
      "[2022-11-07 17:02:06] 240 loss = 0.00000214, mse = 0.00003970\n",
      "[2022-11-07 17:02:08] 250 loss = 0.00000214, mse = 0.00003970\n",
      "[2022-11-07 17:02:11] 260 loss = 0.00000214, mse = 0.00003970\n",
      "[2022-11-07 17:02:13] 270 loss = 0.00000214, mse = 0.00003970\n",
      "[2022-11-07 17:02:15] 280 loss = 0.00000214, mse = 0.00003970\n",
      "[2022-11-07 17:02:17] 290 loss = 0.00000214, mse = 0.00003970\n",
      "imidx_list: [6174]\n",
      "gt_label: [2810] lab_iDLG: 2810\n",
      "----------------------\n",
      "\n",
      "\n",
      "running 7|1000 experiment\n",
      "IDLG, Try to generate 1 images\n",
      "lr = 1.0\n",
      "[2022-11-07 17:02:22] 0 loss = 28.07974243, mse = 1.12893164\n",
      "[2022-11-07 17:02:39] 10 loss = 0.64097667, mse = 0.43445501\n",
      "[2022-11-07 17:02:53] 20 loss = 0.08381530, mse = 0.14967266\n",
      "[2022-11-07 17:03:04] 30 loss = 0.01488295, mse = 0.04782681\n",
      "[2022-11-07 17:03:16] 40 loss = 0.00322095, mse = 0.01589304\n",
      "[2022-11-07 17:03:27] 50 loss = 0.00081965, mse = 0.00586083\n",
      "[2022-11-07 17:03:38] 60 loss = 0.00027276, mse = 0.00237724\n",
      "[2022-11-07 17:03:50] 70 loss = 0.00009429, mse = 0.00090661\n",
      "[2022-11-07 17:04:03] 80 loss = 0.00003333, mse = 0.00033486\n",
      "[2022-11-07 17:04:20] 90 loss = 0.00001239, mse = 0.00012529\n",
      "[2022-11-07 17:04:37] 100 loss = 0.00000478, mse = 0.00005065\n",
      "[2022-11-07 17:04:52] 110 loss = 0.00000183, mse = 0.00001988\n",
      "[2022-11-07 17:05:08] 120 loss = 0.00000089, mse = 0.00000970\n",
      "imidx_list: [12711]\n",
      "gt_label: [5477] lab_iDLG: 5477\n",
      "----------------------\n",
      "\n",
      "\n",
      "running 8|1000 experiment\n",
      "IDLG, Try to generate 1 images\n",
      "lr = 1.0\n",
      "[2022-11-07 17:05:10] 0 loss = 36.44613647, mse = 1.24308205\n",
      "[2022-11-07 17:05:30] 10 loss = 1.05797327, mse = 0.50610310\n",
      "[2022-11-07 17:05:46] 20 loss = 0.12191502, mse = 0.17364359\n",
      "[2022-11-07 17:06:03] 30 loss = 0.02335336, mse = 0.06796096\n",
      "[2022-11-07 17:06:20] 40 loss = 0.00533463, mse = 0.02888707\n",
      "[2022-11-07 17:06:37] 50 loss = 0.00172562, mse = 0.01428875\n",
      "[2022-11-07 17:06:53] 60 loss = 0.00063736, mse = 0.00735397\n",
      "[2022-11-07 17:07:13] 70 loss = 0.00029135, mse = 0.00432847\n",
      "[2022-11-07 17:07:31] 80 loss = 0.00014970, mse = 0.00253654\n",
      "[2022-11-07 17:07:51] 90 loss = 0.00007797, mse = 0.00140306\n",
      "[2022-11-07 17:08:09] 100 loss = 0.00004123, mse = 0.00077395\n",
      "[2022-11-07 17:08:26] 110 loss = 0.00002162, mse = 0.00041665\n",
      "[2022-11-07 17:08:44] 120 loss = 0.00001319, mse = 0.00025861\n",
      "[2022-11-07 17:08:58] 130 loss = 0.00000814, mse = 0.00015300\n",
      "[2022-11-07 17:09:15] 140 loss = 0.00000486, mse = 0.00008705\n",
      "[2022-11-07 17:09:28] 150 loss = 0.00000304, mse = 0.00004987\n",
      "[2022-11-07 17:09:42] 160 loss = 0.00000193, mse = 0.00003066\n",
      "[2022-11-07 17:09:56] 170 loss = 0.00000137, mse = 0.00002121\n",
      "[2022-11-07 17:10:06] 180 loss = 0.00000106, mse = 0.00001621\n",
      "[2022-11-07 17:10:08] 190 loss = 0.00000106, mse = 0.00001621\n",
      "[2022-11-07 17:10:10] 200 loss = 0.00000106, mse = 0.00001621\n",
      "[2022-11-07 17:10:12] 210 loss = 0.00000106, mse = 0.00001621\n",
      "[2022-11-07 17:10:14] 220 loss = 0.00000106, mse = 0.00001621\n",
      "[2022-11-07 17:10:16] 230 loss = 0.00000106, mse = 0.00001621\n",
      "[2022-11-07 17:10:18] 240 loss = 0.00000106, mse = 0.00001621\n",
      "[2022-11-07 17:10:20] 250 loss = 0.00000106, mse = 0.00001621\n",
      "[2022-11-07 17:10:22] 260 loss = 0.00000106, mse = 0.00001621\n",
      "[2022-11-07 17:10:24] 270 loss = 0.00000106, mse = 0.00001621\n",
      "[2022-11-07 17:10:26] 280 loss = 0.00000106, mse = 0.00001621\n",
      "[2022-11-07 17:10:28] 290 loss = 0.00000106, mse = 0.00001621\n",
      "imidx_list: [3811]\n",
      "gt_label: [1804] lab_iDLG: 1804\n",
      "----------------------\n",
      "\n",
      "\n",
      "running 9|1000 experiment\n",
      "IDLG, Try to generate 1 images\n",
      "lr = 1.0\n",
      "[2022-11-07 17:10:31] 0 loss = 74.23899841, mse = 1.28834748\n",
      "[2022-11-07 17:10:44] 10 loss = 0.99209666, mse = 0.36330447\n",
      "[2022-11-07 17:10:57] 20 loss = 0.06584662, mse = 0.09020823\n",
      "[2022-11-07 17:11:09] 30 loss = 0.00934398, mse = 0.02736430\n",
      "[2022-11-07 17:11:23] 40 loss = 0.00216407, mse = 0.00913479\n",
      "[2022-11-07 17:11:37] 50 loss = 0.00051226, mse = 0.00290709\n",
      "[2022-11-07 17:11:50] 60 loss = 0.00015445, mse = 0.00121132\n",
      "[2022-11-07 17:12:03] 70 loss = 0.00005517, mse = 0.00059270\n",
      "[2022-11-07 17:12:17] 80 loss = 0.00002281, mse = 0.00034604\n",
      "[2022-11-07 17:12:30] 90 loss = 0.00001160, mse = 0.00023477\n",
      "[2022-11-07 17:12:44] 100 loss = 0.00000721, mse = 0.00017507\n",
      "[2022-11-07 17:12:57] 110 loss = 0.00000515, mse = 0.00013266\n",
      "[2022-11-07 17:13:10] 120 loss = 0.00000371, mse = 0.00009491\n"
     ]
    }
   ],
   "source": [
    "for idx_net in range(num_exp):\n",
    "    net.apply(weights_init)\n",
    "\n",
    "    print('running %d|%d experiment'%(idx_net, num_exp))\n",
    "    net = net.to(device)\n",
    "    idx_shuffle = np.random.permutation(len(dst))\n",
    "\n",
    "    print('%s, Try to generate %d images' % ('IDLG', num_dummy))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    imidx_list = []\n",
    "\n",
    "    for imidx in range(num_dummy):\n",
    "        idx = idx_shuffle[imidx]\n",
    "        imidx_list.append(idx)\n",
    "        tmp_datum = tt(dst[idx][0]).float().to(device)\n",
    "        tmp_datum = tmp_datum.view(1, *tmp_datum.size())\n",
    "        tmp_label = torch.Tensor([dst[idx][1]]).long().to(device)\n",
    "        tmp_label = tmp_label.view(1, )\n",
    "        if imidx == 0:\n",
    "            gt_data = tmp_datum\n",
    "            gt_label = tmp_label\n",
    "        else:\n",
    "            gt_data = torch.cat((gt_data, tmp_datum), dim=0)\n",
    "            gt_label = torch.cat((gt_label, tmp_label), dim=0)\n",
    "\n",
    "\n",
    "    # compute original gradient\n",
    "    out = net(gt_data)\n",
    "    y = criterion(out, gt_label)\n",
    "    dy_dx = torch.autograd.grad(y, net.parameters())\n",
    "    original_dy_dx = list((_.detach().clone() for _ in dy_dx))\n",
    "\n",
    "    # generate dummy data and label\n",
    "    dummy_data = torch.randn(gt_data.size()).to(device).requires_grad_(True)\n",
    "    dummy_label = torch.randn((gt_data.shape[0], num_classes)).to(device).requires_grad_(True)\n",
    "\n",
    "    optimizer = torch.optim.LBFGS([dummy_data, ], lr=lr)\n",
    "    # predict the ground-truth label\n",
    "    label_pred = torch.argmin(torch.sum(original_dy_dx[-2], dim=-1), dim=-1).detach().reshape((1,)).requires_grad_(False)\n",
    "\n",
    "    history = []\n",
    "    history_iters = []\n",
    "    losses = []\n",
    "    mses = []\n",
    "    train_iters = []\n",
    "\n",
    "    print('lr =', lr)\n",
    "    for iters in range(Iteration):\n",
    "\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            pred = net(dummy_data)\n",
    "            dummy_loss = criterion(pred, label_pred)\n",
    "\n",
    "            dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
    "\n",
    "            grad_diff = 0\n",
    "            for gx, gy in zip(dummy_dy_dx, original_dy_dx):\n",
    "                grad_diff += ((gx - gy) ** 2).sum()\n",
    "            grad_diff.backward()\n",
    "            return grad_diff\n",
    "\n",
    "        optimizer.step(closure)\n",
    "        current_loss = closure().item()\n",
    "        train_iters.append(iters)\n",
    "        losses.append(current_loss)\n",
    "        mses.append(torch.mean((dummy_data-gt_data)**2).item())\n",
    "\n",
    "\n",
    "        if iters % int(Iteration / 30) == 0:\n",
    "            current_time = str(time.strftime(\"[%Y-%m-%d %H:%M:%S]\", time.localtime()))\n",
    "            print(current_time, iters, 'loss = %.8f, mse = %.8f' %(current_loss, mses[-1]))\n",
    "            history.append([tp(dummy_data[imidx].cpu()) for imidx in range(num_dummy)])\n",
    "            history_iters.append(iters)\n",
    "\n",
    "            for imidx in range(num_dummy):\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                plt.subplot(3, 10, 1)\n",
    "                plt.imshow(tp(gt_data[imidx].cpu()))\n",
    "                for i in range(min(len(history), 29)):\n",
    "                    plt.subplot(3, 10, i + 2)\n",
    "                    plt.imshow(history[i][imidx])\n",
    "                    plt.title('iter=%d' % (history_iters[i]))\n",
    "                    plt.axis('off')\n",
    "                plt.savefig('%s/iDLG_on_%s_%05d.png' % (save_path, imidx_list, imidx_list[imidx]))\n",
    "                plt.close()\n",
    "\n",
    "            if current_loss < 0.000001: # converge\n",
    "                break\n",
    "\n",
    "    loss_iDLG = losses\n",
    "    label_iDLG = label_pred.item()\n",
    "    mse_iDLG = mses\n",
    "\n",
    "\n",
    "\n",
    "    print('imidx_list:', imidx_list)\n",
    "    print('gt_label:', gt_label.detach().cpu().data.numpy(), 'lab_iDLG:', label_iDLG)\n",
    "\n",
    "    print('----------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e6903b",
   "metadata": {},
   "source": [
    "## Test codes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
